{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn import svm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvNames = ['Well1B3mths.csv','Well1C3mths.csv','Well1D3mths.csv','Well1E3mths.csv',\n",
    "           'Well1F3mths.csv','Well1G3mths.csv','Well1H3mths.csv','Well1I3mths.csv',\n",
    "           'Well1J3mths.csv','Well2A3mths.csv','Well2B3mths.csv','Well2C3mths.csv',\n",
    "            'Well2D3mths.csv','Well2E3mths.csv','Well3A3mths.csv','Well3B3mths.csv',\n",
    "            'Well3C3mths.csv','Well3D3mths.csv','Well3E3mths.csv','Well3F3mths.csv',\n",
    "            'Well3G3mths.csv','Well3H3mths.csv','Well3I3mths.csv','Well4A3mths.csv',\n",
    "            'Well4B3mths.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresColNames = ['Casing Pressure',\n",
    "                    'Gas Flow (Volume)',\n",
    "                    'Motor Speed',\n",
    "                    'Motor Torque',\n",
    "                    'Pump Speed Actual', #this contains NULLs\n",
    "                    'Tubing Flow Meter',\n",
    "                    'Tubing Pressure',\n",
    "                    'Water Flow Mag from Separator']\n",
    "targetsName = ['Downhole Gauge Pressure']\n",
    "\n",
    "allFeatures = []\n",
    "allTargets = []\n",
    "\n",
    "for well in csvNames:\n",
    "    df = pd.DataFrame.from_csv(well)\n",
    "    \n",
    "    features = df[featuresColNames].dropna()\n",
    "    target = df[targetsName].dropna()\n",
    "    \n",
    "    allFeatures.append(features)\n",
    "    allTargets.append(target)\n",
    "\n",
    "allFeatures = pd.concat(allFeatures).as_matrix()\n",
    "allTargets = pd.concat(allTargets).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Features and Targets into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the arrays\n",
      "trainSize is:  305640\n",
      "testSize is:  130988\n",
      "separating them into trainX, trainY, testX, testY\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Split into trainingX, trainingY, testX, testY\n",
    "\n",
    "# shuffle these arrays so that training and test sets are randomized\n",
    "print \"shuffling the arrays\"\n",
    "allFeatures = random.sample(allFeatures, len(allFeatures)) \n",
    "allTargets = random.sample(allTargets, len(allTargets))\n",
    "\n",
    "# percentage to train on\n",
    "sampleSize = 0.1\n",
    "\n",
    "trainSize = int(0.7*len(allFeatures)*sampleSize)\n",
    "testSize = int(0.3*len(allFeatures)*sampleSize)\n",
    "print \"trainSize is: \", trainSize\n",
    "print \"testSize is: \", testSize\n",
    "\n",
    "print \"separating them into trainX, trainY, testX, testY\"\n",
    "trainX = allFeatures[:trainSize]\n",
    "trainY = allTargets[:trainSize]\n",
    "testX = allFeatures[trainSize:trainSize+testSize]\n",
    "testY = allTargets[trainSize:trainSize+testSize]\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Machine Learning (with sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR()\n",
    "clf.fit(trainX, trainY) \n",
    "predictions = clf.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Percentage of Error \n",
    "\n",
    "Go through each example and calculate the percentage of error. Add this percentage of error to an array. Then use this array to calculate the overall percentage of error within the predicted test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall error was: 51.8173081805%\n"
     ]
    }
   ],
   "source": [
    "def calculateError(prediction, actual):\n",
    "    return (predicted-actual)/actual\n",
    "\n",
    "percentageErrors = []\n",
    "for i, prediction in enumerate(predictions):\n",
    "    actual = testY[i][0]\n",
    "    percentageError = (prediction-actual)/actual\n",
    "    percentageErrors.append(percentageError)\n",
    "\n",
    "overallError = np.sum(percentageErrors) / len(percentageErrors)\n",
    "\n",
    "print \"Overall error was: \" + str(overallError*100) + \"%\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
